{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import pefile\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import StratifiedKFold as KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(vector, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(vector, f)\n",
    "\n",
    "def get_label_table(path):\n",
    "    table = dict()\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            md5, label = line.strip().split(\",\")\n",
    "            table[md5] = int(label)\n",
    "    return table\n",
    "\n",
    "def load_vectors(base_path):\n",
    "    vectors, labels = [], []\n",
    "    for path in tqdm(glob.glob(base_path)):\n",
    "        md5 = os.path.basename(path)[:-4]\n",
    "        vectors.append(load_pickle(path))\n",
    "        labels.append(label_table[md5+'.vir'])\n",
    "    return np.array(vectors), np.array(labels)\n",
    "\n",
    "word_to_index = load_pickle(\"word_to_index.pkl\")\n",
    "index_to_word = load_pickle(\"index_to_word.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 5\n",
    "SEED = 41\n",
    "\n",
    "def cross_validation(X, y):\n",
    "    kf = KFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n",
    "\n",
    "    accs, precs, recs, f1s = [], [], [], []\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    target_hashs = []\n",
    "    target_X = []\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_valid = X[train_idx], X[test_idx]\n",
    "        y_train, y_valid = y[train_idx], y[test_idx]\n",
    "\n",
    "        clf = RandomForestClassifier(random_state=SEED, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict = clf.predict(X_valid)\n",
    "\n",
    "        accs.append(accuracy_score(y_valid, predict))\n",
    "        precs.append(precision_score(y_valid, predict))\n",
    "        recs.append(recall_score(y_valid, predict))\n",
    "        f1s.append(f1_score(y_valid, predict))\n",
    "    return np.average(accs), np.average(precs), np.average(recs),np.average(f1s)\n",
    "\n",
    "def iat_embedding(functions, how):\n",
    "    n_features = len(embedding_table[0])\n",
    "    embedded_vector = np.zeros(n_features)\n",
    "    for function in functions:\n",
    "        if function in word_to_index:\n",
    "            index = word_to_index[function]\n",
    "        else:\n",
    "            index = word_to_index[\"<unk>\"]\n",
    "            \n",
    "        if how == \"max\":\n",
    "            embedded_vector = np.maximum(embedded_vector, embedding_table[index])\n",
    "        else:\n",
    "            embedded_vector = np.minimum(embedded_vector, embedding_table[index])\n",
    "    return embedded_vector.tolist()\n",
    "\n",
    "\n",
    "def iat_feature_hashing(functions, n_features):\n",
    "    feature_vector = [0] * n_features\n",
    "    for impstr in functions:\n",
    "        hash_value = int(hashlib.sha256(impstr.encode()).hexdigest(), 16)\n",
    "        feature_vector[hash_value & (n_features - 1)] += 1\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def load_iat_with_processing(base_path, processing, n_features):\n",
    "    vectors, labels = [], []\n",
    "    for path in tqdm(glob.glob(base_path)):\n",
    "        md5 = os.path.basename(path)[:-4]\n",
    "        if processing == \"embedding\":\n",
    "            vectors.append(iat_embedding(load_pickle(path), how=\"max\"))\n",
    "        else:\n",
    "            vectors.append(iat_feature_hashing(load_pickle(path), n_features))\n",
    "        labels.append(label_table[md5+'.vir'])\n",
    "    return np.array(vectors), np.array(labels)\n",
    "\n",
    "\n",
    "def load_header_iat_with_processing(base_path, processing, n_features):\n",
    "    vectors, labels = [], []\n",
    "    for header_path, iat_path in tqdm(base_path):\n",
    "        md5 = os.path.basename(header_path)[:-4]\n",
    "        header_vector = load_pickle(header_path)\n",
    "        \n",
    "        if processing == \"embedding\":\n",
    "            iat_vector = iat_embedding(load_pickle(iat_path), how=\"max\")\n",
    "        else:\n",
    "            iat_vector = iat_feature_hashing(load_pickle(iat_path), n_features)\n",
    "        \n",
    "        vectors.append(header_vector + iat_vector)\n",
    "        labels.append(label_table[md5+'.vir'])\n",
    "    return np.array(vectors), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only IAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6005fbc792dd4b778581a7b9795cec06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FH 200 (0.9162956713339167, 0.9337115399813681, 0.9504195804195804, 0.9419883656686471)\n"
     ]
    }
   ],
   "source": [
    "label_table = get_label_table(\"label.csv\")\n",
    "n_features = 200\n",
    "X_fh, y_fh = load_iat_with_processing(\"data/FeatureVector/iat_vector/*\", \"fh\", n_features)\n",
    "\n",
    "print(\"FH 200\", cross_validation(X_fh, y_fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc38de43e6a9473ea81a04bc355abd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FH 100 (0.91409564008001, 0.9315729976945881, 0.9496153846153847, 0.9405065465276229)\n"
     ]
    }
   ],
   "source": [
    "n_features = 100\n",
    "X_fh, y_fh = load_iat_with_processing(\"data/FeatureVector/iat_vector/*\", \"fh\", n_features)\n",
    "\n",
    "print(\"FH 100\", cross_validation(X_fh, y_fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc53fc583e4456aa161165c9baf2a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding 200 maximum (0.8828940461307664, 0.8875011041854528, 0.9576223776223778, 0.9212266820076284)\n"
     ]
    }
   ],
   "source": [
    "embedding_table = torch.load(\"Pretrained_Apicall_Vector_200.pkl\")\n",
    "n_features = len(embedding_table[0])\n",
    "X_emb, y_emb = load_iat_with_processing(\"data/FeatureVector/iat_vector/*\", \"embedding\", n_features)\n",
    "\n",
    "\n",
    "print(f\"Embedding {n_features} maximum\", cross_validation(X_emb, y_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364c60740cfb4f999f0c9922487db0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding 100 maximum (0.8832940930116265, 0.888086084990231, 0.9574475524475524, 0.9214606194066342)\n"
     ]
    }
   ],
   "source": [
    "embedding_table = torch.load(\"Pretrained_Apicall_Vector_100.pkl\")\n",
    "n_features = len(embedding_table[0])\n",
    "X_emb, y_emb = load_iat_with_processing(\"data/FeatureVector/iat_vector/*\", \"embedding\", n_features)\n",
    "\n",
    "print(f\"Embedding {n_features} maximum\", cross_validation(X_emb, y_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header + IAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a950f34571be4f16a25fc9e127df56ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FH 200 (0.9640980997624704, 0.9679584292715069, 0.9823076923076923, 0.9750790387716487)\n"
     ]
    }
   ],
   "source": [
    "label_table = get_label_table(\"label.csv\")\n",
    "n_features = 200\n",
    "X_fh, y_fh = load_header_iat_with_processing(list(zip(glob.glob(r\"data/FeatureVector/header_vector/*\"), glob.glob(r\"data/FeatureVector/iat_vector/*\"))), \"fh\", n_features)\n",
    "\n",
    "print(\"FH 200\", cross_validation(X_fh, y_fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ecd0afefdf4537b75f6de5316565d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FH 100 (0.963423093511689, 0.9671872944175863, 0.9821678321678322, 0.9746182830954115)\n"
     ]
    }
   ],
   "source": [
    "n_features = 100\n",
    "X_fh, y_fh = load_header_iat_with_processing(list(zip(glob.glob(r\"data/FeatureVector/header_vector/*\"), glob.glob(r\"data/FeatureVector/iat_vector/*\"))), \"fh\", n_features)\n",
    "\n",
    "print(\"FH 100\", cross_validation(X_fh, y_fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab802b62820446bcb2897dd07ccdd222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding 200 maximum (0.9638981403925492, 0.9673699243959369, 0.9826573426573427, 0.9749532462059266)\n"
     ]
    }
   ],
   "source": [
    "embedding_table = torch.load(\"Pretrained_Apicall_Vector_200.pkl\")\n",
    "n_features = len(embedding_table[0])\n",
    "X_emb, y_emb = load_header_iat_with_processing(list(zip(glob.glob(r\"data/FeatureVector/header_vector/*\"), glob.glob(r\"data/FeatureVector/iat_vector/*\"))), \"embedding\", n_features)\n",
    "\n",
    "\n",
    "print(f\"Embedding {n_features} maximum\", cross_validation(X_emb, y_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d39cc98e2b347689ae3ea082bc2b810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39998), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding 100 maximum (0.9645481153894236, 0.9683356165706545, 0.9825524475524474, 0.9753905839567109)\n"
     ]
    }
   ],
   "source": [
    "embedding_table = torch.load(\"Pretrained_Apicall_Vector_100.pkl\")\n",
    "n_features = len(embedding_table[0])\n",
    "X_emb, y_emb = load_header_iat_with_processing(list(zip(glob.glob(r\"data/FeatureVector/header_vector/*\"), glob.glob(r\"data/FeatureVector/iat_vector/*\"))), \"embedding\", n_features)\n",
    "\n",
    "\n",
    "print(f\"Embedding {n_features} maximum\", cross_validation(X_emb, y_emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
